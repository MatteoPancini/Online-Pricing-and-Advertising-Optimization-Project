{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Learning for Pricing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the case in which all the users belong to class C1. Assume that the curves related to the advertising part of the problem are known, while the curve related to the pricing problem is not. Apply the UCB1 and TS algorithms, reporting the plots of the average (over a sufficiently large number of runs) value and standard deviation of the cumulative regret, cumulative reward, instantaneous regret, and instantaneous reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import pandas as pd\n",
    "from User_Classes import UserClass\n",
    "from UCB import *\n",
    "from Learner import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Pricing_Environment import *\n",
    "from TS_Learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc1 = UserClass(name = \"C1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Advertising_Environment.generate_observations() got an unexpected keyword argument 'class_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,T):\n\u001b[0;32m     22\u001b[0m     \u001b[39m#Thompson sampling\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     pulled_arm \u001b[39m=\u001b[39m ts_learner\u001b[39m.\u001b[39mpull_arm()\n\u001b[1;32m---> 24\u001b[0m     reward \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mround(class_index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, price_index\u001b[39m=\u001b[39;49mpulled_arm)\n\u001b[0;32m     25\u001b[0m     ts_learner\u001b[39m.\u001b[39mupdate(pulled_arm, reward)\n\u001b[0;32m     27\u001b[0m     \u001b[39m# Greedy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Andrea\\Documents\\GitHub\\OLA_2023_Private\\Project-Pricing-Advertising-2022-2023\\Pricing_Environment.py:26\u001b[0m, in \u001b[0;36mEnvironment_Pricing.round\u001b[1;34m(self, class_index, price_index)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mround\u001b[39m(\u001b[39mself\u001b[39m, class_index, price_index):\n\u001b[0;32m     25\u001b[0m     prices \u001b[39m=\u001b[39m [\u001b[39m50\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m150\u001b[39m,\u001b[39m200\u001b[39m,\u001b[39m250\u001b[39m]\n\u001b[1;32m---> 26\u001b[0m     clicks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mad_env\u001b[39m.\u001b[39;49mgenerate_observations(noise_std_clicks\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, bid\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, class_index\u001b[39m=\u001b[39;49mclass_index)\n\u001b[0;32m     27\u001b[0m     conversion_prob \u001b[39m=\u001b[39m classes[class_index]\u001b[39m.\u001b[39mget_conversion_probabilities()[price_index]\n\u001b[0;32m     28\u001b[0m     margin \u001b[39m=\u001b[39m prices[price_index] \u001b[39m-\u001b[39m (prices[price_index]\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m30\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Advertising_Environment.generate_observations() got an unexpected keyword argument 'class_index'"
     ]
    }
   ],
   "source": [
    "n_arms = 5\n",
    "\n",
    "p = uc1.get_conversion_probabilities()\n",
    "env = Environment_Pricing(n_arms=n_arms, p = p)\n",
    "prices = env.prices\n",
    "\n",
    "opt = p[0] #optimal arm is the one with the highest probability of success\n",
    "\n",
    "T = 365 #time steps for each experiment \n",
    "\n",
    "n_experiments = 1000\n",
    "\n",
    "ts_rewards_per_experiment = [] #list to store the collected rewards for TS_Learner over each experiment\n",
    "ucb_reward_per_experiment = [] #list to store the collected rewards for Greedy_Learner over each experiment\n",
    "\n",
    "# Loop over the experiments\n",
    "for e in range (0, n_experiments):\n",
    "    env = Environment_Pricing(n_arms=n_arms, p = p)\n",
    "    ts_learner = TS_Learner(n_arms=n_arms)\n",
    "    ucb_learner = UCB(n_arms=n_arms)\n",
    "    for t in range(0,T):\n",
    "        #Thompson sampling\n",
    "        pulled_arm = ts_learner.pull_arm()\n",
    "        reward = env.round(class_index=0, price_index=pulled_arm)\n",
    "        ts_learner.update(pulled_arm, reward)\n",
    "\n",
    "        # Greedy\n",
    "        pulled_arm = ucb_learner.pull_arm()\n",
    "        reward = env.round(class_index=0, price_index = pulled_arm)\n",
    "        ucb_learner.update(pulled_arm, reward)\n",
    "\n",
    "\n",
    "    ts_rewards_per_experiment.append(ts_learner.collected_rewards)\n",
    "    ucb_reward_per_experiment.append(ucb_learner.collected_rewards)\n",
    "\n",
    "\"\"\"\n",
    "plt.figure(0)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt - ts_rewards_per_experiment, axis = 0)), 'r')\n",
    "plt.plot(np.cumsum(np.mean(opt - gr_reward_per_experiment, axis = 0)), 'g')\n",
    "plt.legend([\"TS\", \"Greedy\"])\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# Compute the mean and standard deviation of the cumulative reward at each round\n",
    "mean_cum_reward_ts = np.mean(ts_rewards_per_experiment, axis=0)\n",
    "std_cum_reward_ts = np.std(ts_rewards_per_experiment, axis=0)\n",
    "\n",
    "mean_cum_reward_ucb = np.mean(ucb_reward_per_experiment, axis=0)\n",
    "std_cum_reward_ucb = np.std(ucb_reward_per_experiment, axis=0)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(range(1, T+1), mean_cum_reward_ts, label='TS')\n",
    "\n",
    "plt.plot(range(1, T+1), mean_cum_reward_ucb, label='UCB')\n",
    "\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.title('Cumulative Reward over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
